{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\bensk\\AppData\\Local\\Continuum\\anaconda3\\lib\\tkinter\\__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"<ipython-input-1-177ce2266e50>\", line 288, in <lambda>\n",
      "    tk.Button(self, text=\"Import and clean data ready to use\", command = lambda: parse_clean()).pack()\n",
      "  File \"<ipython-input-1-177ce2266e50>\", line 94, in parse_clean\n",
      "    myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
      "NameError: name 'pymongo' is not defined\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "import the three tables into python\n",
    "this code appears to have a lot repeating and so would seem a candidate for a function, but there's a lot of vairety, there\n",
    "is only one repeating identical line in the 4, therefore I decided to write seperately \n",
    "''' \n",
    "\n",
    "def load_csv_mongo():\n",
    "    client = MongoClient()\n",
    "    db=client.food_hs\n",
    "\n",
    "    inv = db.inventory\n",
    "    df = pd.read_csv(\"Inventroy.csv\")\n",
    "    records_ = df.to_dict(orient = 'records')\n",
    "    result = db.inv.insert_many(records_ )\n",
    "\n",
    "    ins = db.inspections\n",
    "    df = pd.read_csv(\"Inspections.csv\")\n",
    "    records_ = df.to_dict(orient = 'records')\n",
    "    result = db.ins.insert_many(records_ )\n",
    "\n",
    "    vio = db.violations\n",
    "    df = pd.read_csv(\"violations.csv\")\n",
    "    records_ = df.to_dict(orient = 'records')\n",
    "    result = db.vio.insert_many(records_ )\n",
    "\n",
    "def parse_clean():\n",
    "    global inspect\n",
    "    global invent\n",
    "    global violat\n",
    "    client = MongoClient()\n",
    "    db = client['food_hs']\n",
    "    inspect = pd.DataFrame(list(db.ins.find({})))\n",
    "    invent = pd.DataFrame(list(db.inv.find({})))\n",
    "    violat = pd.DataFrame(list(db.vio.find({})))\n",
    "    \n",
    "    #remove any rows which have only 'na' values. This is both for now and for when users add data later\n",
    "    inspect.dropna(how='all')\n",
    "    invent.dropna(how='all')\n",
    "    violat.dropna(how='all')\n",
    "\n",
    "    #replace # with space in inventroy and inspections in set columns, as some columns have # as part of the legitamate string\n",
    "    invent['OWNER ADDRESS']=invent['OWNER ADDRESS'].str.replace('#',' ')\n",
    "    invent['OWNER CITY']=invent['OWNER CITY'].str.replace('#',' ')\n",
    "    invent['FACILITY CITY']=invent['FACILITY CITY'].str.replace('#',' ')\n",
    "    invent['FACILITY ADDRESS']=invent['FACILITY ADDRESS'].str.replace('#',' ')\n",
    "    \n",
    "    inspect['FACILITY CITY']=inspect['FACILITY CITY'].str.replace('#',' ')\n",
    "    inspect['FACILITY ADDRESS']=inspect['FACILITY ADDRESS'].str.replace('#',' ')\n",
    "\n",
    "    #in 4 columns in inverntroy pandas has replaced ' ' with the placeholder &#160; (#is removed above) so I am replacing \n",
    "    #these with space. I am only doing this for these columns as this is the only place it occurs, and so will save \n",
    "    #searching 26 fields, just the 4 necessary. Inspections has the same in 2 columns\n",
    "    invent['OWNER ADDRESS']=invent['OWNER ADDRESS'].str.replace('& 160;',' ')\n",
    "    invent['OWNER CITY']=invent['OWNER CITY'].str.replace('& 160;',' ')\n",
    "    invent['FACILITY CITY']=invent['FACILITY CITY'].str.replace('& 160;',' ')\n",
    "    invent['FACILITY ADDRESS']=invent['FACILITY ADDRESS'].str.replace('& 160;',' ')\n",
    "    \n",
    "    inspect['FACILITY CITY']=inspect['FACILITY CITY'].str.replace('& 160;',' ')\n",
    "    inspect['FACILITY ADDRESS']=inspect['FACILITY ADDRESS'].str.replace('& 160;',' ')\n",
    "\n",
    "    #remove all inactives from inspections\n",
    "    inspect = inspect[inspect['PROGRAM STATUS']!= 'INACTIVE']\n",
    "\n",
    "    # Convert eg 08/23/2018 from string to datetime this allows for the analysis later\n",
    "    inspect['ACTIVITY DATE'] =  pd.to_datetime(inspect['ACTIVITY DATE'], format='%m/%d/%Y')\n",
    "\n",
    "    #make new column for the risk values\n",
    "    inspect['RISK LEVEL']=inspect['PE DESCRIPTION'].values\n",
    "\n",
    "    #only retain the risk level string in RISK LEVEL column\n",
    "    inspect['RISK LEVEL'] = inspect['RISK LEVEL'].str.split('SEATS ').str[1].str.strip()\n",
    "\n",
    "    #remove all categories of risk from PE DESCRIPTION\n",
    "\n",
    "    inspect['PE DESCRIPTION'] = inspect['PE DESCRIPTION'].str.replace('MODERATE RISK' , '')\n",
    "    inspect['PE DESCRIPTION'] = inspect['PE DESCRIPTION'].str.replace('HIGH RISK' , '')\n",
    "    inspect['PE DESCRIPTION'] = inspect['PE DESCRIPTION'].str.replace('LOW RISK' , '')\n",
    "    \n",
    "    #remove dupicates from all datasets , this is to check for future problems\n",
    "    violat=violat.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "    inspect=inspect.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "    invent=invent.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "\n",
    "    #delete dirty data and parse clean datasets to Mongo\n",
    "    myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    mydb = myclient[\"food_hs\"]\n",
    "    mycol1 = mydb[\"inv\"]\n",
    "    mycol2 = mydb[\"ins\"]\n",
    "    mycol3 = mydb[\"vio\"]\n",
    "\n",
    "    mycol1.drop()\n",
    "    mycol2.drop()\n",
    "    mycol3.drop()\n",
    "\n",
    "    client = MongoClient()\n",
    "    db=client.food_hs\n",
    "\n",
    "    inv = db.inventory\n",
    "    records_ = invent.to_dict(orient = 'records')\n",
    "    result = db.inv.insert_many(records_ )\n",
    "\n",
    "    ins = db.inventory\n",
    "    records_ = inspect.to_dict(orient = 'records')\n",
    "    result = db.ins.insert_many(records_ )\n",
    "\n",
    "    vio = db.inventory\n",
    "    records_ = violat.to_dict(orient = 'records')\n",
    "    result = db.vio.insert_many(records_ )\n",
    "\n",
    "def violations_score():    \n",
    "    #new df merged from vio and ins for use to see score and number of violations by establishment\n",
    "    num_df = pd.merge(violat, inspect, on = 'SERIAL NUMBER')\n",
    "\n",
    "    #new column which holds the amount of vioaltions an esablishment has been guilt of\n",
    "    num_df['VIOLATIONS'] = num_df.groupby('FACILITY ID')['FACILITY ID'].transform('count')\n",
    "\n",
    "    #sort the num_df by date\n",
    "    num_df = pd.DataFrame(num_df.sort_values(by='ACTIVITY DATE'))\n",
    "    \n",
    "    num_df = num_df[['SERIAL NUMBER','FACILITY ID','FACILITY NAME','SCORE','VIOLATIONS']]\n",
    "    num_df = pd.DataFrame(num_df.drop_duplicates('FACILITY ID', keep = 'last'))\n",
    "\n",
    "    #make result df just shows the two relevant columns\n",
    "    num_df = num_df[['SCORE','VIOLATIONS']]\n",
    "\n",
    "    #sort the values on violations ready for graphing\n",
    "    num_df.sort_values('VIOLATIONS', axis = 0, ascending = True, \n",
    "                     inplace = True, na_position ='last') \n",
    "    \n",
    "    #select and store all records with more than 300 violations\n",
    "    indexNames = num_df[num_df['VIOLATIONS'] > 200].index\n",
    "\n",
    "    # Delete these row indexes from dataFrame\n",
    "    num_df.drop(indexNames , inplace=True)\n",
    "    \n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    x = num_df.SCORE\n",
    "    y = num_df.VIOLATIONS\n",
    "    \n",
    "    plt.scatter(x, y)\n",
    "    plt.title('Violations and current score')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Violations')\n",
    "    plt.savefig('score_violations.jpg', bbox_inches='tight') \n",
    "    plt.show() \n",
    "    plt.close()\n",
    "        \n",
    "    window = Tk()\n",
    "    im = Image.open('score_violations.jpg')\n",
    "    ph = ImageTk.PhotoImage(im)\n",
    "    label = Label(window, image=ph)\n",
    "    label.image=ph\n",
    "    tk.Label(root, image =label).pack\n",
    "    tk.Button(root, text=\"Return to averages menu\", command=lambda: root.destroy()).pack()\n",
    "\n",
    "    \n",
    "def facility_count_vio():\n",
    "    #new df merged from vio and ins for use to see score and number of violations by establishment\n",
    "    num_df = pd.merge(violat, inspect, on = 'SERIAL NUMBER')\n",
    "\n",
    "    #new column which holds the amount of vioaltions an esablishment has been guilt of\n",
    "    num_df['VIOLATIONS'] = num_df.groupby('FACILITY ID')['FACILITY ID'].transform('count')\n",
    "\n",
    "    #sort the num_df by date\n",
    "    num_df = pd.DataFrame(num_df.sort_values(by='ACTIVITY DATE'))\n",
    "    \n",
    "    num_df = num_df[['SERIAL NUMBER','FACILITY ID','FACILITY NAME','SCORE','VIOLATIONS']]\n",
    "    num_df = pd.DataFrame(num_df.drop_duplicates('FACILITY ID', keep = 'last'))\n",
    "\n",
    "    #sort the values on violations ready for graphing\n",
    "    num_df.sort_values('VIOLATIONS', axis = 0, ascending = True, \n",
    "                     inplace = True, na_position ='last') \n",
    "    \n",
    "    #select and store all records with more than 300 violations\n",
    "    indexNames = num_df[num_df['VIOLATIONS'] > 200].index\n",
    "\n",
    "    x = num_df.VIOLATIONS\n",
    "    count = num_df['VIOLATIONS'].value_counts() \n",
    "    plt.bar(count, x)\n",
    "    plt.show() \n",
    "    plt.savefig('score_facility.png', bbox_inches='tight')    \n",
    "    plt.close()\n",
    "    \n",
    "def average_all():\n",
    "    #create new dataframes which contain each years records \n",
    "    ins17 = inspect[inspect['ACTIVITY DATE'].isin(pd.date_range('2017-01-01','2017-12-31'))]\n",
    "    ins18 = inspect[inspect['ACTIVITY DATE'].isin(pd.date_range('2018-01-01','2018-12-31'))]\n",
    "    ins19 = inspect[inspect['ACTIVITY DATE'].isin(pd.date_range('2019-01-01','2019-12-31'))]\n",
    "    global averages_all\n",
    "    averages_all = (\"Mean for 2017: \",ins17[\"SCORE\"].mean(),\"\\n\",\"Median for 2017: \",ins17[\"SCORE\"].median(),\"\\n\", \n",
    "                    \"Mode for 2017: \",ins17[\"SCORE\"].mode()\n",
    "                    \n",
    "                    ,\"\\n\\n\",\"Mean for 2018: \",ins18[\"SCORE\"].mean(),\"\\n\",\"Median for 2018: \",ins18[\"SCORE\"].median(),\n",
    "                    \"\\n\"\"Mode for 2018: \",ins18[\"SCORE\"].mode()\n",
    "                    \n",
    "                    ,\"\\n\\n\",\"Mean for 2019: \",ins19[\"SCORE\"].mean(),\"\\n\",\"Median for 2019: \",ins19[\"SCORE\"].median(),\n",
    "                    \"\\n\",\"Mode for 2019: \",ins19[\"SCORE\"].mode())\n",
    "    \n",
    "def averages(city,year):\n",
    "    def calculate():\n",
    "        city_df = merge_df.loc[merge_df['FACILITY CITY_x']==city]\n",
    "        mean_city = city_df[\"SCORE\"].mean()\n",
    "        mode_city = city_df[\"SCORE\"].mode()\n",
    "        median_city = city_df[\"SCORE\"].median()\n",
    "        global averages\n",
    "        \n",
    "        mean_text = (city,\" mean \",year,\":\", mean_city)\n",
    "        median_text = (city,\" median \",year,\":\",median_city)\n",
    "        mode_text = (city,\" mode \",year,\":\",mode_city) \n",
    "        averages = (mean_text,\"\\n\",median_text,\"\\n\",mode_text,\"\\n\")\n",
    "        \n",
    "    if year == '2017':\n",
    "        ins17 = inspect[inspect['ACTIVITY DATE'].isin(pd.date_range('2017-01-01','2017-12-31'))]\n",
    "        merge_df = pd.merge(invent, ins17, how='inner', on = 'RECORD ID')\n",
    "        calculate()\n",
    "    elif year == '2018':\n",
    "        ins18 = inspect[inspect['ACTIVITY DATE'].isin(pd.date_range('2018-01-01','2018-12-31'))]\n",
    "        merge_df = pd.merge(invent, ins18, how='inner', on = 'RECORD ID')\n",
    "        calculate()    \n",
    "    elif year == '2019':\n",
    "        ins19 = inspect[inspect['ACTIVITY DATE'].isin(pd.date_range('2019-01-01','2019-12-31'))]\n",
    "        merge_df = pd.merge(invent, ins19, how='inner', on = 'RECORD ID')\n",
    "        calculate()\n",
    "\n",
    "class GUI_app(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "        self._frame = None\n",
    "        self.switch_frame(StartPage)\n",
    "\n",
    "    def switch_frame(self, frame_class):\n",
    "        \"\"\"Destroys current frame and replaces it with a new one.\"\"\"\n",
    "        new_frame = frame_class(self)\n",
    "        if self._frame is not None:\n",
    "            self._frame.destroy()\n",
    "        self._frame = new_frame\n",
    "        self._frame.pack()\n",
    "\n",
    "def City_Av():\n",
    "    root = Tk()\n",
    "    options = inspect['FACILITY CITY'].unique().tolist()     \n",
    "\n",
    "    root.title(\"Please select city and year\")\n",
    "    root.geometry(\"400x200\")\n",
    "\n",
    "    var_city = StringVar(root)\n",
    "    var_city.set(options[0]) # default value\n",
    "    var_year = StringVar(root) \n",
    "    var_year.set('2017')\n",
    "    dd1 = OptionMenu(root, var_city, *options).pack()\n",
    "    dd2 = OptionMenu(root, var_year, '2017','2018','2019').pack()\n",
    "    def label():\n",
    "            tk.Label(root,text = averages).pack()\n",
    "    \n",
    "    def run_averages():\n",
    "        location = var_city.get()\n",
    "        date = var_year.get()\n",
    "        averages(location,date)\n",
    "        label()\n",
    "\n",
    "    tk.Button(root, text=\"Calculate averages\", command=lambda: run_averages()).pack()\n",
    "    tk.Button(root, text=\"Return to averages menu\", command=lambda: root.destroy()).pack()\n",
    "\n",
    "def Av_all():\n",
    "    root = Tk()\n",
    "    average_all()\n",
    "    tk.Label(root, text=averages_all).pack(side=\"top\", fill=\"x\", pady=10)\n",
    "    tk.Button(root, text=\"Return to averages menu\", command=lambda: root.destroy()).pack()\n",
    "\n",
    "class StartPage(tk.Frame):\n",
    "    def __init__(self, master):\n",
    "        tk.Frame.__init__(self, master)\n",
    "        tk.Label(self, text=\"Welcome\").pack(side=\"top\", fill=\"x\", pady=10)\n",
    "        master.title(\"Main Menu\")\n",
    "        master.geometry(\"350x190\")\n",
    "        tk.Button(self, text=\"Transfer csv to mongoDB\", command = lambda: load_csv_mongo()).pack()        \n",
    "        tk.Button(self, text=\"Import and clean data ready to use\", command = lambda: parse_clean()).pack()\n",
    "        tk.Button(self, text=\"Averages\", command=lambda: master.switch_frame(Averages)).pack()\n",
    "        tk.Button(self, text=\"Visualise correlation between score and violations\", command=lambda: violations_score()).pack()\n",
    "        tk.Button(self, text=\"Visualise establishment and number of violations\", command=lambda: facility_count_vio()).pack()\n",
    "        \n",
    "class Averages(tk.Frame):\n",
    "    def __init__(self, master):\n",
    "        tk.Frame.__init__(self, master)\n",
    "        tk.Label(self, text=\"Welcome to the averages page\").pack(side=\"top\", fill=\"x\", pady=10)\n",
    "        tk.Button(self, text=\"Averages for all\", command=lambda: Av_all()).pack()\n",
    "        tk.Button(self, text=\"Averages for cities\", command=lambda: City_Av()).pack()\n",
    "        tk.Button(self, text=\"Return to start page\",\n",
    "                  command=lambda: master.switch_frame(StartPage)).pack()\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    app = GUI_app()\n",
    "    app.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
